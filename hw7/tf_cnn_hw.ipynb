{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dxaYLOwNfxI"
   },
   "source": [
    "<span style=\"font-size: 14pt\">MIPT, Advanced ML, Spring 2018</span>\n",
    "\n",
    "<span style=\"font-size: 16pt\"> HW #7: CNN models\n",
    "\n",
    "<span style=\"color:blue; font-size: 12pt\">Sergey Kolesnikov</span>,\n",
    "<span style=\"color:blue; font-size: 12pt; font-family: 'Verdana'\"> scitator@gmail.com</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfScg9OhNfxK"
   },
   "source": [
    "<h1 align=\"center\">Organization Info</h1> \n",
    "\n",
    "* Дедлайн **27 апреля 2018 23:59** для всех групп.\n",
    "* В качестве решения задания нужно прислать ноутбук с подробными комментариями (<span style='color:red'> без присланного решения результат контеста не будет засчитан </span>).\n",
    "* <span style='color:red'>Название команды в контесте должно соответствовать шаблону: НомерГруппы_Имя_Фамилия, например, 594_Ivan_Ivanov</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lhVFFCNeNfxL"
   },
   "source": [
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2018_fall_<номер_группы>_<фамилия>``, к примеру -- ``ML2018_fall_495_ivanov``\n",
    "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер>.ipnb, к примеру`` -- ``ivanov_401_task7.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2018_fall Question <Содержание вопроса>``\n",
    "\n",
    "\n",
    "--------\n",
    "- **PS1:** Используются автоматические фильтры, и просто не найдем ваше дз, если вы неаккуратно его подпишите.\n",
    "- **PS2:**  Просроченный дедлайн снижает максимальный вес задания по формуле, указнной на первом семинаре\n",
    "- **PS3:** Допустимы исправление кода предложенного кода ниже, если вы считаете"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FHo-XPSxNfxN"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaHodr4-NfxO"
   },
   "source": [
    "<h1 align=\"center\">Check Questions </h1> \n",
    "\n",
    "Ниже приводится список вопросов, с ответами на которые может быть полезно разобраться для понимания темы.\n",
    "\n",
    "**Вопрос 1**: Чем отличаются современные сверточные сети от сетей 5 летней давности?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**Вопрос 2**: Какие неприятности могут возникнуть во время обучения современных нейросетей?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "\n",
    "**Вопрос 3**: У вас есть очень маленький датасет из 100 картинок, классификация, но вы очень хотите использовать нейросеть, какие неприятности вас ждут и как их решить? что делать если первый вариант  решения не заработает?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**Вопрос 4**: Можно ли сделать стайл трансфер для музыки и как?\n",
    "\n",
    "<Ответ>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cwLeZ__JNfxP"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2f7nT5i-NfxQ"
   },
   "source": [
    "<h1 align=\"center\">Theory Questions</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMvHF5VoNfxQ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhFR3igCNfxR"
   },
   "source": [
    "### Useful notebooks\n",
    "#### Colab link (seminar): https://colab.research.google.com/drive/18xjvLspViCwTUXTBNiz_xKxlUblQuGPU\n",
    "#### Colab link (hw): https://colab.research.google.com/drive/1FlYpA-JHCZ1UilPScC2zWhZNCkE3Sv78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEOXTMmKNfxS"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6r4U82-eNfxS"
   },
   "source": [
    "# CIFAR Quest\n",
    "\n",
    "(please read it at least diagonally)\n",
    "\n",
    "* The ultimate quest is to create a network that has as high __accuracy__ as you can push it.\n",
    "* There is a __mini-report__ at the end that you will have to fill in. We recommend reading it first and filling it while you iterate.\n",
    " \n",
    "## Grading\n",
    "* starting at zero points\n",
    "* +2 for describing your iteration path in a report below.\n",
    "* +2 for correct check questions\n",
    "* +1 for beating each of these milestones on __TEST__ dataset:\n",
    "    * 60% (5 total)\n",
    "    * 65% (6 total)\n",
    "    * 70% (7 total)\n",
    "    * 75% (8 total)\n",
    "    * 80% (9 total)\n",
    "    * 82% (10 total)\n",
    "* +2 for really cool solution:\n",
    "    * 84% (12 total)\n",
    "    * 86% (14 total)\n",
    "    * 88% (16 total)\n",
    "    * 90% (18 total)\n",
    "    * 92% (20 total)\n",
    "    \n",
    "## Bonus points\n",
    "\n",
    "Common ways to get bonus points are:\n",
    "* Get higher score, obviously.\n",
    "* Anything special about your NN. For example \"A super-small/fast NN that gets 80%\" gets a bonus.\n",
    "* Any detailed analysis of the results. (saliency maps, whatever)\n",
    "\n",
    "## Restrictions\n",
    "* Please do __NOT__ use pre-trained networks for this assignment.\n",
    " * In other words, milestones must be beaten without pre-trained nets (and such net must be present in the e-mail).\n",
    "* you __can__ use validation data for training, but you __can't'__ do anything with test data apart from running the evaluation procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCPCLY0qNfxT"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16492,
     "status": "ok",
     "timestamp": 1525084223277,
     "user": {
      "displayName": "Irina Dmitriyeva",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "101773001433992323021"
     },
     "user_tz": -180
    },
    "id": "ybh_6p8xNfxU",
    "outputId": "f63805cd-7007-4c44-a950-e2be095701c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  162M  100  162M    0     0  18.0M      0  0:00:09  0:00:09 --:--:-- 13.4M\n",
      "cifar-10-batches-py/\n",
      "cifar-10-batches-py/data_batch_4\n",
      "cifar-10-batches-py/readme.html\n",
      "cifar-10-batches-py/test_batch\n",
      "cifar-10-batches-py/data_batch_3\n",
      "cifar-10-batches-py/batches.meta\n",
      "cifar-10-batches-py/data_batch_2\n",
      "cifar-10-batches-py/data_batch_5\n",
      "cifar-10-batches-py/data_batch_1\n"
     ]
    }
   ],
   "source": [
    "# Load data. It may work slow.\n",
    "!mkdir cifar10\n",
    "!curl -o cifar-10-python.tar.gz https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xvzf cifar-10-python.tar.gz -C cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "W1tnUujzNfxW"
   },
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1525084192090,
     "user": {
      "displayName": "Irina Dmitriyeva",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "101773001433992323021"
     },
     "user_tz": -180
    },
    "id": "KAgVSAWHNfxY",
    "outputId": "456234e8-a4ee-432c-c679-4eda224e5c31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1298,
     "status": "ok",
     "timestamp": 1525084194365,
     "user": {
      "displayName": "Irina Dmitriyeva",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "101773001433992323021"
     },
     "user_tz": -180
    },
    "id": "m-BNJhkGNfxZ",
    "outputId": "38db7bec-6e64-4620-e1f0-d40dcaedfcb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1VFQpIvNNfxb"
   },
   "outputs": [],
   "source": [
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\" load single batch of cifar \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f, encoding='iso-8859-1')\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "        return X, Y\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)    \n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ext8mi04Nfxc"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "\n",
    "cifar10_dir = './cifar10/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "i-b2r8hgdfBi"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.transpose(0, 2, 3, 1)\n",
    "X_test  = X_test.transpose(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1525084254252,
     "user": {
      "displayName": "Irina Dmitriyeva",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "101773001433992323021"
     },
     "user_tz": -180
    },
    "id": "8JO5N_XnGTc1",
    "outputId": "efa78c85-6cc0-42ca-bd7d-40d6ab58b7fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.70756512369792\n",
      "121.52915475260417\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_train))\n",
    "print(np.mean(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mZPNLsnGdgdb"
   },
   "outputs": [],
   "source": [
    "# X_train /= 255.\n",
    "# X_test /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DIdCAmy6GTdI"
   },
   "outputs": [],
   "source": [
    "train_min = X_train.min(axis=(0, 1), keepdims=True)\n",
    "train_max = X_train.max(axis=(0, 1), keepdims=True)\n",
    "X_train = (X_train - train_min)/(train_max - train_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yxtkSk0MGTdL"
   },
   "outputs": [],
   "source": [
    "test_min = X_test.min(axis=(0, 1), keepdims=True)\n",
    "test_max = X_test.max(axis=(0, 1), keepdims=True)\n",
    "X_test = (X_test - test_min)/(test_max - test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1525084266407,
     "user": {
      "displayName": "Irina Dmitriyeva",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "101773001433992323021"
     },
     "user_tz": -180
    },
    "id": "C07Vh4FhGTdO",
    "outputId": "42dfb8bd-df85-4137-89d1-4416d926851d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4733630004850874\n",
      "0.47658492059844665\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_train))\n",
    "print(np.mean(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 665,
     "status": "error",
     "timestamp": 1525041769824,
     "user": {
      "displayName": "Irina Dmitriyeva",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "101773001433992323021"
     },
     "user_tz": -180
    },
    "id": "6sCttNT0Nfxd",
    "outputId": "2b6b636c-44dc-4f49-e730-be01287384c0"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a46a8b3392c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mplt_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_per_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3099\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3100\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3101\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3102\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3103\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5129\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5131\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5132\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    620\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    621\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFgAAABSCAYAAADQDhNSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAA7dJREFUeJztnD+IXFUUh7+fiVpsoaBbiAYiGLKksDCDWAoiJBZJoUXSaCSyjcHaTrCzEgRRVgxRC42kWkEQxMJGJbMgYgzCIoiDgusf0giRhZ/FvI3LZrLvGu+Zt2/2fDCwb+7dN4ePy2PPnjNHtkniuKXrAGadFBxMCg4mBQeTgoNJwcG0CpZ0VtKvkr69wbokvSZpVdI3kh6qH2Z/KTnB54Aj26wfBQ40r0Xgjf8f1uzQKtj258Af22w5DrzrMV8Cd0q6p1aAfafGM/he4KdN16PmvQTYW+EemvDexPxb0iLjxwhzc3OHFxYWKnz89FlZWfnN9nzJ3hqCR8C+Tdf3AT9P2mh7CVgCGAwGHg6HFT5++kj6sXRvjUfEMvB089fEI8AV279UuO9M0HqCJb0PPArcLWkEvATcCmD7TeBj4AlgFfgLeDYq2D7SKtj2yZZ1A89Xi2jGyEwumBQcTAoOJgUHk4KDScHBpOBgUnAwKTiYFBxMCg4mBQeTgoNJwcGk4GCKBEs6Iun7pvfhxQnrpyStSfq6eT1XP9R+UlLR2AO8DjzOuP52UdKy7e+2bD1v+0xAjL2m5AQ/DKza/sH238AHjHshkgJKBJf2PTzZtE5dkLRvwjqSFiUNJQ3X1tZuItz+USK4pO/hI2C/7QeBT4F3Jt3I9pLtge3B/HxRW0HvKRHc2vdg+3fbV5vLt4DDdcLrPyWCLwIHJN0v6TbgBONeiGts6UU7BlyuF2K/KSnbr0s6A3wC7AHO2r4k6WVgaHsZeEHSMWCdcaPgqcCYe4W6+hpXz1unVmwPSvZmJhdMCg4mBQeTgoNJwcGk4GBScDApOJgUHEwKDiYFB5OCg0nBwaTgYGqV7W+XdL5Z/0rS/tqB9pWSeREbZfujwCHgpKRDW7adBv60/QDwKvBK7UD7Sq2y/XH+LXReAB6TNKlYuuuoVba/tsf2OnAFuKtGgH2n5Nv2JWX7opEGm8cZAFdvNKamBxws3VgiuGRcwcaekaS9wB1MmJKyeZyBpGFpXWunIam4mFilbN9cP9P8/BTwmXMoJlCvbP828J6kVcYn90Rk0H2is7K9pMXmkdE7/kvsnQneLWSqHEwngttS751K2xTESUxdcGHqvVM5x/ZTEK+jixPc2475gimI19GF4F01KbALwcWTAmeBLgQXTwqcBboQXJJ6zwxTF9z8O3Mj9b4MfGj70rTjuBmaKYhfAAcljSSdbv2dzORiyUwumBQcTAoOJgUHk4KDScHBpOBgUnAw/wBZGizc4KQl9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1e3c7860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8').transpose(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Jh6oUQRrNfxe"
   },
   "outputs": [],
   "source": [
    "# Write your convolutional NN with Tensorflow (example in seminar).\n",
    "# For example 3 convolutions and poolings and dense layer after that.\n",
    "\n",
    "def get_cnn():\n",
    "   \n",
    "    # Input Layer\n",
    "    input_layer = tf.placeholder(\n",
    "        tf.float32, \n",
    "        shape=[None, 32, 32, 3], \n",
    "        name=\"input\"\n",
    "    )\n",
    "    \n",
    "#     input_layer = tf.reshape(X, [-1, 32, 32, 3])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"SAME\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        inputs=conv1, \n",
    "        pool_size=[2, 2], \n",
    "        strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"SAME\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv2, \n",
    "        pool_size=[2, 2], \n",
    "        strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 8 * 8 * 64])\n",
    "    \n",
    "    dense = tf.layers.dense(\n",
    "        inputs=pool2_flat, \n",
    "        units=1024, \n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    \n",
    "    predictions = tf.argmax(input=logits, axis=1)\n",
    "    \n",
    "    return input_layer, logits, predictions\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = tf.contrib.layers.l2_regularizer(scale=0.0001)\n",
    "\n",
    "def cnn():\n",
    "    IMAGE_SIZE = 32\n",
    "    IMAGE_CHANNELS = 3\n",
    "  \n",
    "    input_layer = tf.placeholder(\n",
    "        tf.float32, \n",
    "        shape=[None, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS], \n",
    "        name=\"input\"\n",
    "    )\n",
    "    \n",
    "    # CONV-POOL #1\n",
    "    conv = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"SAME\",\n",
    "        activation=tf.nn.elu,\n",
    "        kernel_regularizer=l2_reg\n",
    "    )\n",
    "    batch_norm = tf.layers.batch_normalization(\n",
    "        inputs=conv,\n",
    "        axis=3\n",
    "    )\n",
    "    pool = tf.layers.max_pooling2d(\n",
    "        inputs=batch_norm, \n",
    "        pool_size=[2, 2], \n",
    "        strides=2\n",
    "    )\n",
    "    drop = tf.layers.dropout(inputs=pool, rate=0.2)\n",
    "    \n",
    "    # CONV-POOL #2\n",
    "    conv = tf.layers.conv2d(\n",
    "        inputs=drop,\n",
    "        filters=64,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"SAME\",\n",
    "        activation=tf.nn.elu,\n",
    "        kernel_regularizer=l2_reg\n",
    "    )\n",
    "    batch_norm = tf.layers.batch_normalization(\n",
    "        inputs=conv,\n",
    "        axis=3\n",
    "    )\n",
    "    pool = tf.layers.max_pooling2d(\n",
    "        inputs=batch_norm, \n",
    "        pool_size=[2, 2], \n",
    "        strides=2\n",
    "    )\n",
    "    drop = tf.layers.dropout(inputs=pool, rate=0.3)\n",
    "    \n",
    "    # CONV-POOL #3\n",
    "    conv = tf.layers.conv2d(\n",
    "        inputs=drop,\n",
    "        filters=128,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"SAME\",\n",
    "        activation=tf.nn.elu,\n",
    "        kernel_regularizer=l2_reg\n",
    "    )\n",
    "    batch_norm = tf.layers.batch_normalization(\n",
    "        inputs=conv,\n",
    "        axis=3\n",
    "    )\n",
    "    pool = tf.layers.max_pooling2d(\n",
    "        inputs=batch_norm, \n",
    "        pool_size=[2, 2], \n",
    "        strides=2\n",
    "    )\n",
    "    drop = tf.layers.dropout(inputs=pool, rate=0.4)\n",
    "    \n",
    "    # DENSE\n",
    "    flat = tf.reshape(drop, [-1, 4 * 4 * 128])\n",
    "    dense = tf.layers.dense(\n",
    "        inputs=flat, \n",
    "        units=2048, \n",
    "        activation=tf.nn.elu\n",
    "    )\n",
    "    drop = tf.layers.dropout(inputs=dense, rate=0.5)\n",
    "    \n",
    "    # LOGITS\n",
    "    logits = tf.layers.dense(\n",
    "        inputs=drop,\n",
    "        units=10\n",
    "    )\n",
    "    \n",
    "    # PREDICTION\n",
    "    predictions = tf.argmax(input=logits, axis=1)\n",
    "    \n",
    "    # RETURN\n",
    "    return input_layer, logits, predictions\n",
    "\n",
    "# CNN\n",
    "input_x_model, logits_model, predictions_model = get_cnn()\n",
    "\n",
    "# LABELS\n",
    "labels_model = tf.placeholder(tf.int64, name=\"labels\")\n",
    "\n",
    "# ACCURACY\n",
    "correct_predictions = tf.equal(labels_model, predictions_model)\n",
    "accuracy_model = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "# LOSS\n",
    "loss_model = tf.losses.sparse_softmax_cross_entropy(labels=labels_model, logits=logits_model)\n",
    "optimizer_step = tf.train.MomentumOptimizer (\n",
    "                     learning_rate=0.01,\n",
    "                     momentum=0.9,\n",
    "                     use_nesterov=True\n",
    "                 ).minimize(loss_model, global_step=tf.train.get_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(x, y, sess):\n",
    "    '''\n",
    "    returns tuple (loss, accuracy) for model evaluation phase\n",
    "    '''\n",
    "    eval_loss     = sess.run(loss_model,     feed_dict={input_x_model:x, labels_model:y})\n",
    "    eval_accuracy = sess.run(accuracy_model, feed_dict={input_x_model:x, labels_model:y})\n",
    "    \n",
    "    return (eval_loss, eval_accuracy)\n",
    "\n",
    "def train_fn(x, y, sess):\n",
    "    '''\n",
    "    returns tuple (loss, accuracy) for model train phase\n",
    "    '''\n",
    "    \n",
    "    sess.run(optimizer_step, feed_dict={input_x_model:x, labels_model:y})\n",
    "    \n",
    "    return eval_fn(x, y, sess)\n",
    "\n",
    "\n",
    "\n",
    "def predict_fn(x, sess):\n",
    "    '''\n",
    "    returns y_pred for model predict phase\n",
    "    '''\n",
    "    return sess.run(predictions_model, feed_dict={input_x_model:x, labels_model:y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5Ne7en8oNfxf"
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "We51Om0fNfxh"
   },
   "outputs": [],
   "source": [
    "# @TODO: add your code for train&validation metrics plots:\n",
    "#  - epoch loss (train&validation - 2 curves on same figure)\n",
    "#  - epoch accurary (train&validation - 2 curves on same figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1088
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 294832,
     "status": "ok",
     "timestamp": 1525086756491,
     "user": {
      "displayName": "Irina Dmitriyeva",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "101773001433992323021"
     },
     "user_tz": -180
    },
    "id": "Im14F5ZpNfxi",
    "outputId": "ce17fce6-7c11-4366-d872-9632dbd4c23e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10 took 125.878s\n",
      "  train loss:\t\t1.484442\n",
      "  train accuracy:\t\t47.58 %\n",
      "  valid loss:\t\t1.336031\n",
      "  valid accuracy:\t\t51.68 %\n",
      "Epoch 2 of 10 took 119.600s\n",
      "  train loss:\t\t1.028232\n",
      "  train accuracy:\t\t64.47 %\n",
      "  valid loss:\t\t1.097637\n",
      "  valid accuracy:\t\t61.04 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a5c49ea6ac6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtrain_loss_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_loss_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-4a53a8855fa5>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(x, y, sess)\u001b[0m\n\u001b[1;32m     13\u001b[0m     '''\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_x_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10 \n",
    "batch_size = 64\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, batch_size):\n",
    "            inputs, targets = batch\n",
    "            train_loss_batch, train_acc_batch = train_fn(inputs, targets, sess)\n",
    "            train_loss += train_loss_batch\n",
    "            train_acc += train_acc_batch\n",
    "            train_batches += 1\n",
    "#             print('train loss: {}, train acc: {}'.format(train_loss_batch, train_acc_batch))\n",
    "    \n",
    "        # And a full pass over the validation data:\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        valid_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "            inputs, targets = batch\n",
    "            valid_loss_batch, valid_acc_batch = eval_fn(inputs, targets, sess)\n",
    "            valid_loss += valid_loss_batch\n",
    "            valid_acc += valid_acc_batch\n",
    "            valid_batches += 1\n",
    "    \n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  train loss:\\t\\t{:.6f}\".format(train_loss / train_batches))\n",
    "        print(\"  train accuracy:\\t\\t{:.2f} %\".format(train_acc / train_batches * 100))\n",
    "        print(\"  valid loss:\\t\\t{:.6f}\".format(valid_loss / valid_batches))\n",
    "        print(\"  valid accuracy:\\t\\t{:.2f} %\".format(valid_acc / valid_batches * 100))\n",
    "\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "        inputs, targets = batch\n",
    "        _, acc = eval_fn(inputs, targets, sess)\n",
    "        test_acc += acc\n",
    "        test_batches += 1\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test accuracy:\\t\\t{:.2f} %\".format(test_acc / test_batches * 100))\n",
    "\n",
    "    if test_acc / test_batches * 100 > 92.5:\n",
    "        print(\"Achievement unlocked: mage 80 lvl\")\n",
    "    else:\n",
    "        print(\"Feed more!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7znARImBNfxl"
   },
   "source": [
    "### Hi, my name is `...Luke Cifarwalker...`, and here's my story\n",
    "\n",
    "A long ago in a galaxy far far away, when it was still more than an hour before deadline, i got an idea:\n",
    "\n",
    "##### I gonna build a neural network, that\n",
    "будет классифицировать с точностью хотя бы 80%!!!\n",
    "\n",
    "How could i be so naive?!\n",
    "\n",
    "##### One day, with no signs of warning,\n",
    "....\n",
    "\n",
    "##### Finally, after __  iterations, __ mugs of [tea/coffee]\n",
    "* what was the final architecture\n",
    "* as well as training method and tricks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NTCEtshWNfxl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "tf_cnn_hw.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
